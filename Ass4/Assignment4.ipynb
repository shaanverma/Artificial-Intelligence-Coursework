{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4: Neural Networks\n",
    "Shaan Verma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import operator\n",
    "%matplotlib inline\n",
    "from torch import optim\n",
    "from collections import namedtuple\n",
    "from torch.autograd import Variable\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting AlexNet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Transform variable to convert images to the right size\n",
    "transform = transforms.Compose([            #[1]\n",
    " transforms.Resize(256),                    #[2]\n",
    " transforms.CenterCrop(224),                #[3]\n",
    " transforms.ToTensor(),                     #[4]\n",
    " transforms.Normalize(                      #[5]\n",
    " mean=[0.485, 0.456, 0.406],                #[6]\n",
    " std=[0.229, 0.224, 0.225]                  #[7]\n",
    " )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Getting the CIFAR-10 dataset\n",
    "dataset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='data/', train=False, transform=transform)\n",
    "\n",
    "# 10 Classes in CIFAR-10 dataset\n",
    "classes = dataset.classes\n",
    "\n",
    "torch.manual_seed(43)\n",
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size=100\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 )  moving van : 1049\n",
      "2 )  fox squirrel, eastern fox squirrel, Sciurus niger : 604\n",
      "3 )  sorrel : 340\n",
      "4 )  container ship, containership, container vessel : 300\n",
      "5 )  English foxhound : 246\n",
      "6 )  Dandie Dinmont, Dandie Dinmont terrier : 232\n",
      "7 )  thresher, thrasher, threshing machine : 227\n",
      "8 )  Japanese spaniel : 226\n",
      "9 )  milk can : 217\n",
      "10 )  chain saw, chainsaw : 154\n"
     ]
    }
   ],
   "source": [
    "# Getting 1000 possible classes for imagenet from downloaded file\n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    classes = eval(f.read())\n",
    "\n",
    "# Temparary collections\n",
    "holder = []\n",
    "dic = {}\n",
    "current = ''\n",
    "\n",
    "# Iterates through eat batch of the testloader and gets output from AlexNet\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        out = alexnet(images)\n",
    "        #print(out.shape)    \n",
    "\n",
    "\n",
    "        for j in range(0,batch_size):\n",
    "            sorted_out, indices = torch.sort(out,descending=True)\n",
    "            percentage = F.softmax(out,dim=1)[j]*100\n",
    "            results = [(classes[i.item()],percentage[i].item()) for i in indices[j][:5]]\n",
    "            holder.append(results[0][0])\n",
    "\n",
    "# Sorts all classification names\n",
    "holder.sort()\n",
    "\n",
    "# Populate the dictionary\n",
    "for z in holder:\n",
    "    if current != z:\n",
    "        count = 1\n",
    "        dic[z] = count\n",
    "        current = z\n",
    "    else:\n",
    "        count = count + 1\n",
    "        dic[z] = count \n",
    "        current = z\n",
    "        \n",
    "# Sorting the dictionary of classifications\n",
    "sorted_d = dict( sorted(dic.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "# Printing Top 10 classifications from alexNet\n",
    "dicMax = 1\n",
    "for i in sorted_d:\n",
    "    print(dicMax,') ',i,':',sorted_d[i])\n",
    "    dicMax = dicMax + 1\n",
    "    if(dicMax > 10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet   CC  CCC  DD  EF  FES  JS  MC  MV  SL  TTT\n",
      "CIFAR-10                                           \n",
      "AM         0    0   0   0    1   0   0   0   0    0\n",
      "AP         0    0   0   0    0   0   0   1   0    0\n",
      "B          0    0   0   0    0   0   0   0   1    0\n",
      "C          0    1   0   0    0   0   0   0   0    0\n",
      "DG         0    0   1   0    0   0   0   0   0    0\n",
      "DR         0    0   0   1    0   0   0   0   0    0\n",
      "FG         0    0   0   0    0   0   0   0   0    1\n",
      "H          0    0   0   0    0   1   0   0   0    0\n",
      "S          0    0   0   0    0   0   1   0   0    0\n",
      "T          1    0   0   0    0   0   0   0   0    0\n"
     ]
    }
   ],
   "source": [
    "c_y_actu = pd.Series(['AP','AM','B','C','DR','DG','FG','H','S','T'], name='CIFAR-10')\n",
    "c_y_pred = pd.Series(['MV','FES','SL','CCC','EF','DD','TTT','JS','MC','CC'], name='AlexNet')\n",
    "df_confusion = pd.crosstab(c_y_actu, c_y_pred)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/2] loss:0.749: 100%|██████████| 400/400 [06:25<00:00,  1.04it/s]\n",
      "100%|██████████| 100/100 [01:37<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 0.883  val_accuracy: 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[2/2] loss:0.707: 100%|██████████| 400/400 [07:13<00:00,  1.08s/it]\n",
      "100%|██████████| 100/100 [02:07<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 0.715  val_accuracy: 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Start Testing with train partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [08:04<00:00,  1.21s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 3.050\n",
      "Start Testing with valadation partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:05<00:00,  1.26s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.751\n",
      "Start Testing with test partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:05<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "b =[]\n",
    "for layer in model.classifier.children():\n",
    "    b.append(layer)\n",
    "b = b[:-5]\n",
    "\n",
    "b.append(nn.Linear(4096, 10))\n",
    "new_classifier = nn.Sequential(*b)\n",
    "model.classifier = new_classifier\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0002, momentum=0.9)\n",
    "save_path = './AlexNetc.pth'\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "epochs = 2\n",
    "\n",
    "print(\"Start Training\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for i, data in enumerate(train_bar):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        for data in val_bar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            acc += torch.eq(predicted, labels).sum().item()\n",
    "    val_accurate = acc / val_size\n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "# Evaluating using the train partition         \n",
    "print('Finished Training')\n",
    "print('Start Testing with train partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(train_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "test_accurate = acc / 10000\n",
    "print('test_accuracy: %.3f' %(test_accurate))\n",
    "\n",
    "# Evaluating using the validation partition \n",
    "print('Start Testing with valadation partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(val_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "test_accurate = acc / 10000\n",
    "print('test_accuracy: %.3f' %(test_accurate))\n",
    "\n",
    "\n",
    "# Evaluating using the test partition \n",
    "print('Start Testing with test partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "test_accurate = acc / 10000\n",
    "print('test_accuracy: %.3f' %(test_accurate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/2] loss:29.599: 100%|██████████| 400/400 [08:59<00:00,  1.35s/it]\n",
      "100%|██████████| 100/100 [02:15<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 65.055  val_accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[2/2] loss:41.875: 100%|██████████| 400/400 [09:23<00:00,  1.41s/it]\n",
      "100%|██████████| 100/100 [02:20<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 31.221  val_accuracy: 0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Start Testing with training partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [08:51<00:00,  1.33s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 2.771\n",
      "Finished Training\n",
      "Start Testing with validation partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:13<00:00,  1.34s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.690\n",
      "Start Testing with test partition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:13<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "b =[]\n",
    "for layer in model.classifier.children():\n",
    "    b.append(layer)\n",
    "b = b[:-2]\n",
    "\n",
    "b.append(nn.Linear(4096, 10))\n",
    "new_classifier = nn.Sequential(*b)\n",
    "model.classifier = new_classifier\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "save_path = './AlexNetc.pth'\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "epochs = 2\n",
    "\n",
    "print(\"Start Training\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for i, data in enumerate(train_bar):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        for data in val_bar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            acc += torch.eq(predicted, labels).sum().item()\n",
    "    val_accurate = acc / val_size\n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "            \n",
    "print('Finished Training')\n",
    "print('Start Testing with training partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(train_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "test_accurate = acc / 10000\n",
    "print('test_accuracy: %.3f' %(test_accurate))\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print('Start Testing with validation partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(val_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "test_accurate = acc / 10000\n",
    "print('test_accuracy: %.3f' %(test_accurate))\n",
    "\n",
    "\n",
    "print('Start Testing with test partition')\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader)\n",
    "    for data in test_bar:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc += torch.eq(predicted, labels).sum().item()\n",
    "test_accurate = acc / 10000\n",
    "print('test_accuracy: %.3f' %(test_accurate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
